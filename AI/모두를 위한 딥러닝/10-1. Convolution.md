## Convolution
### Convolution
image 위에 kernel (filter)를 stride만큼 이동시키며 element wise 곱하고 더한 값을 출력
![image](https://github.com/pomota/TIL/assets/132712212/0e946fe5-d9eb-48d8-81cd-7a637070584b)

### Stride and Padding
- Stride: filter를 한번에 얼마나 이동할 것인가
- Padding: image 바깥에 추가되는 테두리 칸

### Pytorch nn.Conv2d
```
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)

conv = nn.Conv2d(1,1,3)
# 입력 채널 1/ 출력채널 1/ 커널크기 3*3 (정사각형 아닌 경우 괄호로 표현)
# 입력 채널은 image의 depth, 출력 채널은 kernel의 개수와 같음
```

### 입력의 형태
```
conv = nn.Conv2d(1,1,3)
out = conv(inputs)
```

input type: torch.Tensor

input shape: (N, C, H, W) (batch_size, channel, height, width)

### output의 크기
output size = (input size - filter size + 2*padding) / Stride + 1

### Pooling
![image](https://github.com/pomota/TIL/assets/132712212/5c45388d-0fef-4499-86da-b28a360e86e2)

### MaxPool2d
```
torch.nn.MaxPool2d(kernel_size, stride, padding, dilation, return_indices, ceil_mode)
# kernel size만 잘 설정하면 됨
```

### CNN model 
```
input = torch.Tensor(1,1,28,28)
conv1 = nn.Conv2d(1,5,5)
pool = nn.MaxPool2d(2)
out = conv1(input)
out2 = pool(out)
out.size() # (1, 5, 24, 24)
out2.size() # (1, 5, 12, 12)
```

### Cross Correlation operator
![image](https://github.com/pomota/TIL/assets/132712212/b7fbfc9f-71d5-4925-a24d-d373188d60a7)


- Convolution: filter와 image가 겹치는 정도로 연산, filter를 뒤집고 연산
- Cross-correlation: filter 뒤집지 않은 채로 연산 (연산자: *)
