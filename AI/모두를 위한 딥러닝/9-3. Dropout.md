## Dropout
### Overfitting
underfitting ~ overfitting

overfitting
- train dataset에서는 높은 accuracy
- test dataset에서는 낮은 accuracy

### Overfitting 해결책
- more data
- reduce number of features
- regularization
- dropout

### Dropout
![image](https://github.com/pomota/TIL/assets/132712212/471c603c-cd27-4835-96d4-b9a6ea7eae38)

학습 과정에서 각 layer에 존재하는 node들을 무작위로 dropout

매번 다른 형태의 구조로 학습됨 (네트워크 앙상블 효과)

### Code
```
dropout = torch.nn.Dropout(p=drop_prob) # p는 drop 확률

model = torch.nn.Sequential(linear1, relu, dropout, linear2, relu, dropout,~~~)
```

test set에서는 dropout을 하지 않도록 주의!
```
model.train() # dropout = True

~~~~
with torch.no_grad():
  model.eval() # dropout = False
```
