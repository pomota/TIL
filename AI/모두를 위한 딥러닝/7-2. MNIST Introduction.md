## MNIST Introduction
### MNIST
handwitten digits dataset

![image](https://github.com/pomota/TIL/assets/132712212/59462dba-cd41-4429-b4c2-26b9523750ed)

train_image: 60000장

test_image: 10000장

- 28*28 image
- 1 channel, grey image
- 0 ~ 9 digits
 
### torchvision
pytorch의 유명한 dataset, model architecture, image transformation을 포함

### Reading data
```
import torchvision.datasets as dsets

mnist_train = dsets.MNIST(root="MNIST_data/", train = True, transform = transforms.ToTensor, download = True)
# 파일의 위치, train / test, 어떤 transform 적용할 것인지, root에 데이터 없으면 download
# Pytorch: 0~1 사이의 값, channel, height, width
# 일반적인 이미지: 0~255, height, width, channel

mnist_test = dsets.MNIST(root="MNIST_data/", train = False, transform = transforms.ToTensor, download = True)

data_loader = torch.utils.DataLoader(DataLoader = mnist_train, batch_size = batch_size, shuffle = True, drop_last = True)
# load할 dataset, batch size, 순서 섞기, 남는 데이터 사용하지 않음 (drop_last)

for epoch in range(training_epochs):
  for X, Y in data_loader: # X는 image, Y는 label
    X = X.view(-1, 28*28).to(device) # (B, 1, 28, 28) -> (B, 784)
```

### Epoch / Batch size / Iteration
- Epoch: training set 전체를 사용하면 1 epoch
- Batch size: 1 epoch을 한번에 학습하지 못하여 batch로 잘라서 학습
- Iteration: 1 epoch을 위해 batch size로 몇번 돌아야 하는지

### Softmax classifier
```
linear = torch.nn.Linear(784, 10, bias=True).to(device) # 784를 10개로 classify
training_epochs=15
batch_size=100

criterion = torch.nn.CrossEntropyLoss().to(device)
optimizer = optim.SGD(linear.parameters(), lr=0.1)

for epoch in range(training_epochs):
  avg_cost = 0
  total_batch = len(data_loader)
  for X, Y in data_loader:
    X = X.view(-1, 28*28).to(device)
    optimizer.zero_grad()
    hypothesis = linear(X)
    cost = criterion(hypothesis, Y)
    cost.backward()
    optimizer.step()
    avg_cost += cost / total_batch
```

### Test
```
with torch.no_grad():
  X_test = mnist_test.test_data.view(-1, 28*28). float().to(device)
  Y_test = mnist_test.test_labels.to(device)

  prediction = linear(X_test)
  correct_prediction = torch.argmax(prediction, 1) == Y_test # dim은 reduce할 차
  accuracy = correct_prediction.float().mean()
  print("Accuracy: ", accuracy.item())
```

### Visualization
```
import matplotlib.pyplot as plt
import random

r = random.randint(0, len(minst_test)-1)
X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float().to(device)
Y_single_data = minist_test.test_labels[r:r+1].to(device)

print("Label: ", Y_single_data.item())
prediction = linear(X_single_data)
print("Prediction: ", torch.argmax(prediction, 1).item())

plt.imshow(mnist_test.test_data[r:r+1].view(28, 28), cmap = "Greys", interpolation = "nearest")
plt.show()
# plt.imshow: 현재 figure에 그림, 없으면 figure 생성
# plt.show: 작업을 마치고 plot을 보여줌 (마지막 코드)
```
